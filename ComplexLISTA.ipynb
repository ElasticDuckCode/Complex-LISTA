{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4657fdda-780b-41a6-89bc-23a7b3e896e2",
   "metadata": {
    "id": "4657fdda-780b-41a6-89bc-23a7b3e896e2"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4f57438-6d0e-4c21-8d0a-7a13203fd6e9",
   "metadata": {
    "id": "c4f57438-6d0e-4c21-8d0a-7a13203fd6e9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import importlib\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import norm, pinv, toeplitz\n",
    "from scipy import fft\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "041d5853-5e92-4af4-86b8-c01a2d33509b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "041d5853-5e92-4af4-86b8-c01a2d33509b",
    "outputId": "6156e0ec-6721-4f32-e0ab-0ff69f359cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from numpy import pi, fft\n",
    "import torch\n",
    "from torch.nn.functional import relu, mse_loss, conv1d\n",
    "from torch.nn import Module, Parameter, ReLU\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84ee2045-a70e-4909-a66a-8a0afbde2167",
   "metadata": {
    "id": "84ee2045-a70e-4909-a66a-8a0afbde2167"
   },
   "outputs": [],
   "source": [
    "class ComplexLISTA(Module):\n",
    "    \n",
    "    def __init__(self, M, N, maxit):\n",
    "        super(ComplexLISTA, self).__init__()\n",
    "    \n",
    "        # Real and imaginary Wg and We matricies \n",
    "        self.Wre = torch.nn.Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.Wrg = torch.nn.Parameter(torch.zeros([maxit+1, N, N]), requires_grad=True)\n",
    "        self.Wie = torch.nn.Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.Wig = torch.nn.Parameter(torch.zeros([maxit+1, N, N]), requires_grad=True)\n",
    "        \n",
    "        # alpha and lambda hyper-parameters to LASSO/ISTA\n",
    "        self.theta = torch.nn.Parameter(torch.ones(maxit+1), requires_grad=True)\n",
    "        \n",
    "        # Save the passed values\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.maxit = maxit\n",
    "        self.relu = ReLU()\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, yr, yi, epsilon=1e-10):\n",
    "        \n",
    "        Wret = torch.transpose(self.Wre[0], 0, 1)\n",
    "        Wiet = torch.transpose(self.Wie[0], 0, 1)\n",
    "        Wrgt = torch.transpose(self.Wrg[0], 0, 1)\n",
    "        Wigt = torch.transpose(self.Wig[0], 0, 1)\n",
    "                \n",
    "        # Apply We branch to y to 0-th iteration\n",
    "        zr = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "        zi = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "        \n",
    "        # Apply soft-thresholding according to Eldar's paper.\n",
    "        xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "        xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        \n",
    "        for t in range(1, self.maxit+1):\n",
    "            \n",
    "            Wret = torch.transpose(self.Wre[0], 0, 1)\n",
    "            Wiet = torch.transpose(self.Wie[0], 0, 1)\n",
    "            Wrgt = torch.transpose(self.Wrg[0], 0, 1)\n",
    "            Wigt = torch.transpose(self.Wig[0], 0, 1)\n",
    "        \n",
    "            # Apply We branch to y to t-th iteration\n",
    "            ar = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "            ai = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "            \n",
    "            # Apply Wg branch to x^(t) for t-th iteration\n",
    "            br = torch.matmul(xr, Wrgt) - torch.matmul(xi, Wigt)\n",
    "            bi = torch.matmul(xi, Wrgt) + torch.matmul(xr, Wigt)\n",
    "            \n",
    "            # Add the two branches                                                                           \n",
    "            zr = ar + br\n",
    "            zi = ai + bi\n",
    "            \n",
    "            # Apply soft-thresholding\n",
    "            xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "            xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "            xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "      \n",
    "        return xr, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "AQ25zXsSKs7C",
   "metadata": {
    "id": "AQ25zXsSKs7C"
   },
   "outputs": [],
   "source": [
    "class ComplexLISTA_Toeplitz(Module):\n",
    "    \n",
    "    def __init__(self, M, N, maxit):\n",
    "        super(ComplexLISTA_Toeplitz, self).__init__()\n",
    "    \n",
    "        # Real and imaginary Wg and We matricies \n",
    "        self.Wre = Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.Wie = Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.hrg = Parameter(torch.zeros([maxit+1, 1, 1, N]), requires_grad=True) # dimension such that it works with conv1d\n",
    "        self.hig = Parameter(torch.zeros([maxit+1, 1, 1, N]), requires_grad=True)\n",
    "        \n",
    "        # alpha and lambda hyper-parameters to LASSO/ISTA\n",
    "        self.theta = Parameter(torch.ones(maxit+1), requires_grad=True)\n",
    "        \n",
    "        # Save the passed values\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.maxit = maxit\n",
    "        self.relu = ReLU()\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, yr, yi, epsilon=1e-10):\n",
    "        \n",
    "        Wret = torch.transpose(self.Wre[0], 0, 1)\n",
    "        Wiet = torch.transpose(self.Wie[0], 0, 1)\n",
    "                \n",
    "        # Apply We branch to y to 0-th iteration\n",
    "        zr = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "        zi = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "        \n",
    "        # Apply soft-thresholding according to Eldar's paper.\n",
    "        xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "        xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        \n",
    "        for t in range(1, self.maxit+1):\n",
    "\n",
    "            Wret = torch.transpose(self.Wre[t], 0, 1)\n",
    "            Wiet = torch.transpose(self.Wie[t], 0, 1)\n",
    "            hrgt = self.hrg[t]\n",
    "            higt = self.hig[t]\n",
    "        \n",
    "            # Apply We branch to y to t-th iteration\n",
    "            ar = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "            ai = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "            \n",
    "            # Apply hg conv1d branch to x^(t) for t-th iteration\n",
    "            br = conv1d(xr.unsqueeze(1), hrgt, padding='same') - conv1d(xi.unsqueeze(1), higt, padding='same')\n",
    "            bi = conv1d(xi.unsqueeze(1), hrgt, padding='same') + conv1d(xr.unsqueeze(1), higt, padding='same')\n",
    "            \n",
    "            # Add the two branches                                                                           \n",
    "            zr = ar + br.squeeze(1)\n",
    "            zi = ai + bi.squeeze(1)\n",
    "            \n",
    "            # Apply soft-thresholding\n",
    "            xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "            xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "            xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "      \n",
    "        return xr, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7hsot2JuKzcy",
   "metadata": {
    "id": "7hsot2JuKzcy"
   },
   "outputs": [],
   "source": [
    "class ComplexLISTA_Weights(Module):\n",
    "    \n",
    "    def __init__(self, M, N, maxit):\n",
    "        super(ComplexLISTA_Weights, self).__init__()\n",
    "    \n",
    "        # Real and imaginary Wg and We matricies \n",
    "        self.Wre = Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.Wie = Parameter(torch.zeros([maxit+1, N, M]), requires_grad=True)\n",
    "        self.Wg = Parameter(torch.zeros([maxit+1, M]), requires_grad=True) # dimension such that it works with conv1d\n",
    "        \n",
    "        # alpha and lambda hyper-parameters to LASSO/ISTA\n",
    "        self.theta = Parameter(torch.ones(maxit+1), requires_grad=True)\n",
    "        \n",
    "        # Save the passed values\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        self.maxit = maxit\n",
    "\n",
    "        # Create useful relu layer\n",
    "        self.relu = ReLU()\n",
    "\n",
    "        # Assuming the measurement model\n",
    "        self.complex_exp = lambda x : np.exp(2j*pi*x)\n",
    "        self.fgrid = fft.fftfreq(N)\n",
    "        self.ula = np.arange(M)\n",
    "        self.arg = np.outer(self.ula, 2*pi*self.fgrid)\n",
    "\n",
    "        # Predefine useful matricies\n",
    "        self.C = torch.from_numpy(np.cos(self.arg)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.S = torch.from_numpy(np.sin(self.arg)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.C = Parameter(self.C, requires_grad=False)\n",
    "        self.S = Parameter(self.S, requires_grad=False)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, yr, yi, epsilon=1e-10):\n",
    "        \n",
    "        Wret = torch.transpose(self.Wre[0], 0, 1)\n",
    "        Wiet = torch.transpose(self.Wie[0], 0, 1)\n",
    "                \n",
    "        # Apply We branch to y to 0-th iteration\n",
    "        zr = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "        zi = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "        \n",
    "        # Apply soft-thresholding according to Eldar's paper.\n",
    "        xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "        xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        \n",
    "        for t in range(1, self.maxit+1):\n",
    "\n",
    "            Wret = torch.transpose(self.Wre[t], 0, 1)\n",
    "            Wiet = torch.transpose(self.Wie[t], 0, 1)\n",
    "        \n",
    "            # Apply We branch to y to t-th iteration\n",
    "            ar = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "            ai = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "            \n",
    "            # Apply hg conv1d branch to x^(t) for t-th iteration\n",
    "            hrgt = torch.matmul(self.Wg[t], self.C)\n",
    "            higt = torch.matmul(self.Wg[t], self.S)\n",
    "\n",
    "            br = conv1d(xr.unsqueeze(1), hrgt, padding='same') - conv1d(xi.unsqueeze(1), higt, padding='same')\n",
    "            bi = conv1d(xi.unsqueeze(1), hrgt, padding='same') + conv1d(xr.unsqueeze(1), higt, padding='same')\n",
    "\n",
    "            # Add the two branches                                                                           \n",
    "            zr = ar + br.squeeze(1)\n",
    "            zi = ai + bi.squeeze(1)\n",
    "            \n",
    "            # Apply soft-thresholding\n",
    "            xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "            xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "            xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "      \n",
    "        return xr, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "108cfc93-4e8b-4cdd-9eb6-9792a0ed8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLISTA_Weights_Nested(Module):\n",
    "    \n",
    "    def __init__(self, M1, M2, N, maxit):\n",
    "        super(ComplexLISTA_Weights_Nested, self).__init__()\n",
    "    \n",
    "        # Real and imaginary Wg and We matricies \n",
    "        self.M = M1 + M2\n",
    "        self.Wre = Parameter(torch.zeros([maxit+1, N, self.M]), requires_grad=True)\n",
    "        self.Wie = Parameter(torch.zeros([maxit+1, N, self.M]), requires_grad=True)\n",
    "        self.win = Parameter(torch.zeros([maxit+1, M1]), requires_grad=True) # dimension such that it works with conv1d\n",
    "        self.wout = Parameter(torch.zeros([maxit+1, M2]), requires_grad=True) # dimension such that it works with conv1d\n",
    "\n",
    "        \n",
    "        # alpha and lambda hyper-parameters to LASSO/ISTA\n",
    "        self.theta = Parameter(torch.ones(maxit+1), requires_grad=True)\n",
    "        \n",
    "        # Save the passed values\n",
    "        self.M1 = M1\n",
    "        self.M2 = M2\n",
    "        self.N = N\n",
    "        self.maxit = maxit\n",
    "\n",
    "        # Create useful relu layer\n",
    "        self.relu = ReLU()\n",
    "\n",
    "        # Assuming the measurement model\n",
    "        self.complex_exp = lambda x : np.exp(2j*pi*x)\n",
    "        self.fgrid = fft.fftfreq(N)\n",
    "        \n",
    "        self.inner = np.arange(M1)\n",
    "        self.outer = np.arange(1, M2+1)*(M1)\n",
    "\n",
    "        self.argin = np.outer(self.inner, 2*pi*self.fgrid)\n",
    "        self.argout = np.outer(self.outer, 2*pi*self.fgrid)\n",
    "\n",
    "        # Predefine useful matricies\n",
    "        self.Cin = torch.from_numpy(np.cos(self.argin)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.Sin = torch.from_numpy(np.sin(self.argin)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.Cin = Parameter(self.Cin, requires_grad=False)\n",
    "        self.Sin = Parameter(self.Sin, requires_grad=False)\n",
    "        \n",
    "        self.Cout = torch.from_numpy(np.cos(self.argout)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.Sout = torch.from_numpy(np.sin(self.argout)).to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        self.Cout = Parameter(self.Cout, requires_grad=False)\n",
    "        self.Sout = Parameter(self.Sout, requires_grad=False)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def forward(self, yr, yi, epsilon=1e-10):\n",
    "        \n",
    "        Wret = torch.transpose(self.Wre[0], 0, 1)\n",
    "        Wiet = torch.transpose(self.Wie[0], 0, 1)\n",
    "                \n",
    "        # Apply We branch to y to 0-th iteration\n",
    "        zr = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "        zi = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "        \n",
    "        # Apply soft-thresholding according to Eldar's paper.\n",
    "        xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "        xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[0])\n",
    "        \n",
    "        for t in range(1, self.maxit+1):\n",
    "\n",
    "            Wret = torch.transpose(self.Wre[t], 0, 1)\n",
    "            Wiet = torch.transpose(self.Wie[t], 0, 1)\n",
    "        \n",
    "            # Apply We branch to y to t-th iteration\n",
    "            ar = torch.matmul(yr, Wret) - torch.matmul(yi, Wiet)\n",
    "            ai = torch.matmul(yi, Wret) + torch.matmul(yr, Wiet)\n",
    "            \n",
    "            # Apply hg conv1d branch to x^(t) for t-th iteration\n",
    "            hrgt = torch.matmul(self.win[t], self.Cin) + torch.matmul(self.wout[t], self.Cout)\n",
    "            higt = torch.matmul(self.win[t], self.Sin) + torch.matmul(self.wout[t], self.Sout)\n",
    "\n",
    "            br = conv1d(xr.unsqueeze(1), hrgt, padding='same') - conv1d(xi.unsqueeze(1), higt, padding='same')\n",
    "            bi = conv1d(xi.unsqueeze(1), hrgt, padding='same') + conv1d(xr.unsqueeze(1), higt, padding='same')\n",
    "\n",
    "            # Add the two branches                                                                           \n",
    "            zr = ar + br.squeeze(1)\n",
    "            zi = ai + bi.squeeze(1)\n",
    "            \n",
    "            # Apply soft-thresholding\n",
    "            xabs = torch.sqrt(torch.square(zr) + torch.square(zi) + epsilon)\n",
    "            xr = torch.divide(zr, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "            xi = torch.divide(zi, xabs + epsilon) * self.relu(xabs - self.theta[t])\n",
    "      \n",
    "        return xr, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27e2df59-12ae-49fd-9ee9-af5df29300d5",
   "metadata": {
    "id": "27e2df59-12ae-49fd-9ee9-af5df29300d5"
   },
   "outputs": [],
   "source": [
    "class sparse_dataset(Dataset):\n",
    "    def __init__(self, N, K, Nexamples, sig=0.0, A=None):\n",
    "        self.X = np.zeros((Nexamples, N, 1))\n",
    "        for ii in range(Nexamples):\n",
    "            self.X[ii,...] = self.generate_sparse_vector(N, K)\n",
    "        #self.X *= np.random.randn(*self.X.shape)\n",
    "        self.X = torch.from_numpy(self.X).reshape(Nexamples, N)\n",
    "        self.Y = self.X @ A.T\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.X[i, ...], self.Y[i, ...])\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def generate_sparse_vector(self, N, K):\n",
    "        x = np.zeros((N,1))\n",
    "        x[:K,...] = 1.\n",
    "        np.random.shuffle(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a37dbeb5-7183-4320-ac99-6ac6abc5f95a",
   "metadata": {
    "id": "a37dbeb5-7183-4320-ac99-6ac6abc5f95a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training data\n",
    "maxit = 10\n",
    "M = 64\n",
    "N = 512\n",
    "sig = 0.4\n",
    "epochs = 10\n",
    "batchSize = 20\n",
    "testFreq = 1\n",
    "trainingPoints = 10_000\n",
    "testingPoints = 100\n",
    "sparsityLevel = 5\n",
    "\n",
    "# Create ULA and Nested Array Matricies\n",
    "M1 = M // 2\n",
    "M2 = M - M1\n",
    "\n",
    "inner = np.arange(M1)\n",
    "outer = np.arange(1, M2+1)*(M1)\n",
    "\n",
    "uniform = np.arange(M).reshape(-1,1)\n",
    "nested = np.concatenate([inner, outer]).reshape(-1, 1)\n",
    "\n",
    "fgrid = fft.fftfreq(N).reshape(-1, 1)\n",
    "\n",
    "complex_exp = lambda x : np.exp(1j* 2*np.pi * x )\n",
    "A_u = complex_exp(uniform @ fgrid.T)\n",
    "A_n = complex_exp(nested @ fgrid.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75113438-dfe2-4e79-8f05-0b236e8969b3",
   "metadata": {
    "id": "75113438-dfe2-4e79-8f05-0b236e8969b3"
   },
   "outputs": [],
   "source": [
    "''' Or load'''\n",
    "dataset_training = torch.load(\"training_data.pt\")\n",
    "dataset_testing = torch.load(\"testing_data.pt\")\n",
    "dataloader_training = DataLoader(dataset_training, \n",
    "                                 batch_size = batchSize, shuffle=True)\n",
    "dataloader_testing = DataLoader(dataset_testing, \n",
    "                                 batch_size = testingPoints, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26502555-68f0-45b9-839c-5baf8956dd2f",
   "metadata": {
    "id": "26502555-68f0-45b9-839c-5baf8956dd2f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_training = sparse_dataset(N, sparsityLevel, trainingPoints, A=A_n) # nested\n",
    "# dataloader_training = DataLoader(dataset_training, \n",
    "#                                  batch_size = batchSize, shuffle=True)\n",
    "# dataset_testing = sparse_dataset(N, sparsityLevel, testingPoints, A=A_n) # nested\n",
    "# dataloader_testing = DataLoader(dataset_testing, \n",
    "#                                  batch_size = testingPoints, shuffle=False)\n",
    "# torch.save(dataset_training, \"training_data.pt\")\n",
    "# torch.save(dataset_testing, \"testing_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "596150e5-6a33-4042-89c5-799485cd5850",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "596150e5-6a33-4042-89c5-799485cd5850",
    "outputId": "ff8b7ec5-b845-4656-d274-251283509769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function ComplexLISTA_Weights_Nested.__init__.<locals>.<lambda> at 0x10706ed30>\n"
     ]
    }
   ],
   "source": [
    "batches = int(trainingPoints/batchSize)\n",
    "#print(trainingPoints/batchSize)\n",
    "training_losslist = np.zeros(epochs * batches)\n",
    "testing_losslist = np.zeros(epochs * batches)\n",
    "\n",
    "#model = ComplexLISTA_Weights(M, N, maxit)\n",
    "model = ComplexLISTA_Weights_Nested(M1, M2, N, maxit)\n",
    "\n",
    "model.to(device)\n",
    "# for name, weights in model.named_parameters():\n",
    "#     print(name, weights)\n",
    "#print(model.state_dict())\n",
    "print(model.complex_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a399404-ab10-4076-b234-6a62a1c46392",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a399404-ab10-4076-b234-6a62a1c46392",
    "outputId": "852efb01-aef0-492b-a861-bc4d7f225b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 512]) torch.Size([100, 64])\n",
      "tensor([0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029])\n",
      "tensor([0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029, 0.0029,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0029])\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wg matrix according to Eldar\n",
    "X, Y = dataset_training[:100]\n",
    "print(X.shape, Y.shape)\n",
    "X = X.numpy().T\n",
    "Y = Y.numpy().T\n",
    "XHX = X.T.conj() @ X \n",
    "XHXinv = pinv(XHX)\n",
    "Phi = Y @ XHXinv @ X.T.conj() # conjugates omitted since X will be real\n",
    "PhiH = torch.from_numpy(Phi.conj().T)\n",
    "L = np.max(np.abs(np.linalg.eigvals(Phi.conj().T @ Phi)))\n",
    "\n",
    "#print(model.state_dict()['Wre'])\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'Wre' in name:\n",
    "            param.copy_(1/L * PhiH.real)\n",
    "        if 'Wie' in name:\n",
    "            param.copy_(1/L * PhiH.imag)\n",
    "        if 'win' in name: # for weighted lista\n",
    "            param.copy_(1/L * torch.ones(model.maxit+1, M1))\n",
    "        if 'wout' in name: # for weighted lista\n",
    "            param.copy_(1/L * torch.ones(model.maxit+1, M2))\n",
    "        if 'theta' in name:\n",
    "            param.copy_(0.01/L * torch.ones(model.maxit+1))\n",
    "\n",
    "print(model.state_dict()['win'][0])\n",
    "print(model.state_dict()['wout'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6efcd2d6-5443-46eb-9496-c365d6143d78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6efcd2d6-5443-46eb-9496-c365d6143d78",
    "outputId": "d71e174c-101b-487b-af11-f43b5078d655"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 40/500\t Training Loss: 0.00894060730934143\t Validation Loss: 0.008958042599260807:   0%|                                                                                      | 0/10 [00:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8m/vk9r8ry13w7_dvnyyd4fwy140000gn/T/ipykernel_37956/3680229627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Send through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mxpredr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpredi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpredr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpredi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/arm64/envs/torch-cpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8m/vk9r8ry13w7_dvnyyd4fwy140000gn/T/ipykernel_37956/1092901369.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, yr, yi, epsilon)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mhigt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhrgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhrgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "obj = torch.nn.MSELoss()\n",
    "t = trange(epochs)\n",
    "#t = range(epochs)\n",
    "for e in t:\n",
    "    for i, data in enumerate(dataloader_training):\n",
    "\n",
    "        idx = e * batches + i\n",
    "        x, y = data\n",
    "        \n",
    "        # Split data to real and complex\n",
    "        xr = x.to(torch.float32).to(device)\n",
    "        xi = torch.zeros_like(xr).to(torch.float32).to(device)\n",
    "        \n",
    "        yr = y.real.to(torch.float32).to(device)\n",
    "        yi = y.imag.to(torch.float32).to(device)\n",
    "        \n",
    "        # Send through model\n",
    "        xpredr, xpredi = model(yr, yi)\n",
    "        \n",
    "        loss = obj(xpredr, xr) + obj(xpredi, xi)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            training_losslist[idx] = loss\n",
    "\n",
    "        loss.backward()    \n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        if testFreq and idx % testFreq == 0:\n",
    "            for k, test_data in enumerate(dataloader_testing):\n",
    "                \n",
    "                x, y = test_data\n",
    "                \n",
    "                xr = x.to(torch.float32).to(device)\n",
    "                xi = torch.zeros_like(xr).to(torch.float32).to(device)\n",
    "                \n",
    "                yr = y.real.to(torch.float32).to(device)\n",
    "                yi = y.imag.to(torch.float32).to(device)\n",
    "                \n",
    "                xpredr, xpredi = model(yr, yi)\n",
    "                xpredr = xpredr.detach().cpu()\n",
    "                xpredi = xpredi.detach().cpu()\n",
    "\n",
    "                testing_losslist[idx] += torch.mean((xpredr.cpu() - xr.cpu())**2) + torch.mean((xpredi.cpu() - xi.cpu())**2)\n",
    "\n",
    "        t.set_description(\"Batch: {}/{}\\t Training Loss: {}\\t Validation Loss: {}\".format(i, len(dataloader_training), training_losslist[idx], testing_losslist[idx]), refresh=True)\n",
    "\n",
    "        #clear_output(wait=True)\n",
    "        #print(\"Epoch: {}\\t Batch: {}\\t Training Loss: {}\\t Validation Loss: {}\".format(e, i, training_losslist[idx], testing_losslist[idx]))\n",
    "\n",
    "        #print(\"Epoch: {}\\t Batch: {}\\t Training Loss: {}\\t\".format(e, i, training_losslist[idx]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3d02c-87d5-48db-93d9-b9f700d81b47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "17f3d02c-87d5-48db-93d9-b9f700d81b47",
    "outputId": "4febdb6d-570e-42e3-f06d-872990c0ca08"
   },
   "outputs": [],
   "source": [
    "print(training_losslist[0])\n",
    "plt.semilogy(training_losslist[10:])\n",
    "plt.semilogy(testing_losslist[10:])\n",
    "torch.save(model.state_dict(), \"weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaafb91-8510-4f26-8241-7b37d6f2febc",
   "metadata": {
    "id": "4eaafb91-8510-4f26-8241-7b37d6f2febc"
   },
   "outputs": [],
   "source": [
    "''' or load the weights '''\n",
    "#model.load_state_dict(torch.load(\"model_weights.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf067838-97c3-44d5-976e-7ab7bf006761",
   "metadata": {
    "id": "cf067838-97c3-44d5-976e-7ab7bf006761"
   },
   "outputs": [],
   "source": [
    "x_test, y_test = dataset_testing[2]\n",
    "\n",
    "yr = y_test.real.to(torch.float32).to(device)\n",
    "yi = y_test.imag.to(torch.float32).to(device)\n",
    "\n",
    "yr = yr.unsqueeze(0)\n",
    "yi = yi.unsqueeze(0)\n",
    "\n",
    "xpredr, xpredi = model(yr, yi)\n",
    "# xistar, xistai = model_ista(yr, yi)\n",
    "\n",
    "x_test = x_test.numpy()\n",
    "x_pred = np.zeros_like(x_test, dtype=complex)\n",
    "x_pred.real = xpredr.detach().cpu().numpy()\n",
    "x_pred.imag = xpredi.detach().cpu().numpy()\n",
    "\n",
    "# x_ista = np.zeros_like(x_test, dtype=complex)\n",
    "# x_ista.real = xistar.detach().numpy()\n",
    "# x_ista.imag = xistai.detach().numpy()\n",
    "\n",
    "S_test = np.abs(x_test)\n",
    "S_pred = np.abs(x_pred)\n",
    "# S_ista = np.abs(x_ista)\n",
    "\n",
    "S_test /= S_test.max()\n",
    "S_pred /= S_pred.max()\n",
    "# S_ista /= S_ista.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbbd16-0f57-4f1d-af7f-bec420ba9a73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "5cbbbd16-0f57-4f1d-af7f-bec420ba9a73",
    "outputId": "8f85d722-bb56-425c-fac8-3abdcaac0100"
   },
   "outputs": [],
   "source": [
    "# Plot ULA\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(fft.fftshift(fft.fftfreq(N)), fft.fftshift(S_pred), linewidth=2, label='LISTA')\n",
    "#ax.plot(fft.fftshift(fft.fftfreq(N)), fft.fftshift(S_ista), linewidth=2, label='ISTA')\n",
    "ax.stem(fft.fftshift(fft.fftfreq(N)), fft.fftshift(S_test), 'k', markerfmt='ko', linefmt='k--', label='True',  basefmt=\" \")\n",
    "y1, y2 = ax.get_ylim()\n",
    "#ax.vlines(fft.fftshift(fft.fftfreq(N)[np.nonzero(S_test)]), linestyle='--', ymin=0, ymax=y2, color='k', label='True')\n",
    "ax.set_ylim(0.001, y2)\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_title('')\n",
    "ax.grid(color='#99AABB', linestyle=':')\n",
    "ax.set_facecolor('#CCDDEE')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G6-YzUCTvHKZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6-YzUCTvHKZ",
    "outputId": "435d31c4-391c-4d97-87b9-96c955f53738"
   },
   "outputs": [],
   "source": [
    "abcd = torch.arange(N, dtype=torch.float32, requires_grad=True).unsqueeze(0).unsqueeze(0)\n",
    "efgh = torch.arange(M, dtype=torch.float32, requires_grad=True).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "ijkl = conv1d(abcd, efgh, padding='same')\n",
    "print(abcd.shape)\n",
    "print(efgh.shape)\n",
    "print(ijkl.shape)\n",
    "\n",
    "l = mse_loss(abcd, 2*ijkl)\n",
    "l.backward()\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "mM6Z-abuOwO5",
   "metadata": {
    "id": "mM6Z-abuOwO5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[ 8 16 24 32 40 48 56 64]\n"
     ]
    }
   ],
   "source": [
    "M1 = 8\n",
    "M2 = 8\n",
    "print(np.arange(M1))\n",
    "print(np.arange(1, M2+1)*(M1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3be03-17ab-418b-ac7f-8767bcec2e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ComplexLISTA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:torch-cpu]",
   "language": "python",
   "name": "conda-env-torch-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
